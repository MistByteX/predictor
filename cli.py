#!/usr/bin/env python3
"""
é¢„æµ‹ç³»ç»ŸCLIå·¥å…· - æ”¯æŒæ¢…èŠ±æ˜“æ•°å’Œå¤šAgentæ¨¡æ‹Ÿ
"""
import sys
import os
import json
import re
import argparse
from datetime import datetime
from pathlib import Path
import requests
from algorithms import ALGORITHMS, EnsemblePredictor
from meihua import predict as meihua_predict, format_result as format_meihua

# é…ç½®è·¯å¾„
CONFIG_DIR = Path.home() / ".predictor"
CONFIG_FILE = CONFIG_DIR / "config.json"
TEMPLATES_DIR = Path(__file__).parent / "templates"
PREDICTIONS_DIR = Path(__file__).parent / "predictions"

__version__ = "0.2.0"


def get_config() -> dict:
    if not CONFIG_FILE.exists():
        return {}
    with open(CONFIG_FILE, encoding="utf-8") as f:
        return json.load(f)


def save_config(config: dict):
    CONFIG_DIR.mkdir(parents=True, exist_ok=True)
    with open(CONFIG_FILE, "w", encoding="utf-8") as f:
        json.dump(config, f, ensure_ascii=False, indent=2)


def fill_template(template: str, variables: dict) -> str:
    result = template
    for key, value in variables.items():
        result = result.replace(f"{{{key}}}", str(value))
    unfilled = re.findall(r'\{([^}]+)\}', result)
    if unfilled:
        raise ValueError(f"æœªå¡«å……çš„å˜é‡: {', '.join(unfilled)}")
    return result


class Predictor:
    def __init__(self, glm_api_key: str = None, glm_base_url: str = None):
        config = get_config()
        self.api_key = glm_api_key or config.get("glm_api_key")
        self.base_url = glm_base_url or config.get("glm_base_url", "https://open.bigmodel.cn/api/paas/v4")
        if not self.api_key:
            raise ValueError("è¯·è®¾ç½®GLM API Key: predictor config set api_key <your_key>")
    
    def call_glm(self, prompt: str, system_prompt: str = None) -> str:
        url = f"{self.base_url}/chat/completions"
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        messages.append({"role": "user", "content": prompt})
        
        data = {
            "model": "glm-4-flash",
            "messages": messages,
            "temperature": 0.7
        }
        
        response = requests.post(url, headers=headers, json=data, timeout=120)
        response.raise_for_status()
        result = response.json()
        return result["choices"][0]["message"]["content"]
    
    def create_template(self, name: str, content: str = None, template_file: str = None):
        TEMPLATES_DIR.mkdir(parents=True, exist_ok=True)
        if template_file:
            with open(template_file, encoding="utf-8") as f:
                content = f.read()
        if not content:
            raise ValueError("éœ€è¦æä¾›æ¨¡æ¿å†…å®¹")
        template_path = TEMPLATES_DIR / f"{name}.md"
        with open(template_path, "w", encoding="utf-8") as f:
            f.write(content)
        return str(template_path)
    
    def list_templates(self):
        TEMPLATES_DIR.mkdir(parents=True, exist_ok=True)
        return [f.stem for f in TEMPLATES_DIR.glob("*.md")]
    
    def get_template(self, name: str) -> str:
        template_path = TEMPLATES_DIR / f"{name}.md"
        if not template_path.exists():
            raise FileNotFoundError(f"æ¨¡æ¿ä¸å­˜åœ¨: {name}")
        with open(template_path, encoding="utf-8") as f:
            return f.read()
    
    def predict(self, template_name: str, variables: dict = None, system_prompt: str = None,
                enable_meihua: bool = False, simulate_agents: int = 0) -> dict:
        template = self.get_template(template_name)
        if variables:
            prompt = fill_template(template, variables)
        else:
            prompt = template
        
        # æ¢…èŠ±æ˜“æ•°åˆ†æ
        meihua_result = None
        if enable_meihua:
            question = variables.get("äº‹ä»¶æè¿°", variables.get("äº‹ä»¶", "")) if variables else prompt
            try:
                now = datetime.now()
                meihua_result = meihua_predict(
                    question, 
                    method="time",
                    year=now.year,
                    month=now.month,
                    day=now.day,
                    hour=now.hour
                )
            except Exception as e:
                meihua_result = {"error": str(e)}
        
        # å¤šAgentæ¨¡æ‹Ÿ
        agent_simulations = []
        if simulate_agents > 0:
            for i in range(simulate_agents):
                agent_prompt = f"ä½ æ˜¯æ¨¡æ‹ŸAgent {i+1}ï¼Œè¯·ä»ä½ çš„è§’åº¦åˆ†æè¿™ä¸ªäº‹ä»¶çš„å‘å±•ï¼š\n\n{prompt}"
                try:
                    sim_result = self.call_glm(agent_prompt, system_prompt="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æœªæ¥å­¦å®¶ï¼Œæ“…é•¿åˆ†æäº‹ä»¶å‘å±•è¶‹åŠ¿")
                    agent_simulations.append({
                        "agent_id": i + 1,
                        "analysis": sim_result
                    })
                except Exception as e:
                    agent_simulations.append({
                        "agent_id": i + 1,
                        "error": str(e)
                    })
        
        # ä¸»é¢„æµ‹
        prediction = self.call_glm(prompt, system_prompt)
        
        PREDICTIONS_DIR.mkdir(parents=True, exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        record = {
            "template": template_name,
            "variables": variables or {},
            "prompt": prompt,
            "prediction": prediction,
            "meihua": meihua_result,
            "agent_simulations": agent_simulations,
            "timestamp": timestamp
        }
        
        history_file = PREDICTIONS_DIR / f"{timestamp}.json"
        with open(history_file, "w", encoding="utf-8") as f:
            json.dump(record, f, ensure_ascii=False, indent=2)
        
        return {
            "prompt": prompt,
            "prediction": prediction,
            "meihua": meihua_result,
            "agent_simulations": agent_simulations,
            "history_file": str(history_file)
        }
    
    def history(self, limit: int = 10):
        PREDICTIONS_DIR.mkdir(parents=True, exist_ok=True)
        files = sorted(PREDICTIONS_DIR.glob("*.json"), reverse=True)[:limit]
        records = []
        for f in files:
            with open(f, encoding="utf-8") as fp:
                data = json.load(fp)
                records.append({
                    "timestamp": data["timestamp"],
                    "template": data["template"],
                    "prediction": data["prediction"][:100] + "..."
                })
        return records


def format_output(result: dict, enable_meihua: bool = False, simulate_agents: int = 0) -> str:
    """æ ¼å¼åŒ–è¾“å‡ºç»“æœ"""
    output = []
    output.append("\n" + "="*60)
    output.append("ğŸ“Š é¢„æµ‹ç»“æœ")
    output.append("="*60)
    output.append(result["prediction"])
    
    # æ¢…èŠ±æ˜“æ•°ç»“æœ
    if enable_meihua and result.get("meihua"):
        meihua = result["meihua"]
        if "error" not in meihua:
            output.append("\n" + "="*60)
            output.append("ğŸ”® æ¢…èŠ±æ˜“æ•°åˆ†æ")
            output.append("="*60)
            output.append(format_meihua(meihua))
    
    # å¤šAgentæ¨¡æ‹Ÿç»“æœ
    if simulate_agents > 0 and result.get("agent_simulations"):
        output.append("\n" + "="*60)
        output.append(f"ğŸ¤– å¤šAgentæ¨¡æ‹Ÿ ({simulate_agents}ä¸ªAgent)")
        output.append("="*60)
        for sim in result["agent_simulations"]:
            if "error" not in sim:
                output.append(f"\n--- Agent {sim['agent_id']} åˆ†æ ---")
                output.append(sim["analysis"][:500] + "..." if len(sim["analysis"]) > 500 else sim["analysis"])
    
    output.append("="*60)
    output.append(f"\nğŸ“ å·²ä¿å­˜è‡³: {result['history_file']}")
    
    return "\n".join(output)


def cmd_init(args):
    config = get_config()
    if not config:
        api_key = args.api_key or input("è¯·è®¾ç½®GLM API Key: ").strip()
        if api_key:
            config["glm_api_key"] = api_key
            config["glm_base_url"] = "https://open.bigmodel.cn/api/paas/v4"
            save_config(config)
            print("âœ… é…ç½®å·²ä¿å­˜")
        else:
            print("âŒ éœ€è¦API Key")
            sys.exit(1)
    else:
        print("å·²å­˜åœ¨é…ç½®:", config)
    return 0


def cmd_config(args):
    config = get_config()
    if args.subcommand == "show":
        if config:
            print(json.dumps(config, ensure_ascii=False, indent=2))
        else:
            print("æœªé…ç½®ï¼Œè¯·å…ˆè¿è¡Œ predictor init")
        return 0
    if args.subcommand == "set":
        if args.key == "api_key":
            config["glm_api_key"] = args.value
            save_config(config)
            print(f"âœ… å·²è®¾ç½® glm_api_key")
        elif args.key == "base_url":
            config["glm_base_url"] = args.value
            save_config(config)
            print(f"âœ… å·²è®¾ç½® glm_base_url")
        else:
            print(f"âŒ æœªçŸ¥é…ç½®é¡¹: {args.key}")
            sys.exit(1)
        return 0


def cmd_create_template(args):
    try:
        p = Predictor(glm_api_key=args.api_key)
        path = p.create_template(args.name, template_file=args.file)
        print(f"âœ… æ¨¡æ¿å·²åˆ›å»º: {path}")
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        sys.exit(1)
    return 0


def cmd_list_templates(args):
    try:
        p = Predictor(glm_api_key=args.api_key)
        templates = p.list_templates()
        if templates:
            print("ğŸ“‹ æ¨¡æ¿åˆ—è¡¨:")
            for t in templates:
                print(f"  - {t}")
        else:
            print("æš‚æ— æ¨¡æ¿ï¼Œè¯·å…ˆåˆ›å»º")
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        sys.exit(1)
    return 0


def cmd_predict(args):
    try:
        p = Predictor(glm_api_key=args.api_key)
        variables = None
        if args.variables:
            variables = json.loads(args.variables)
        
        enable_meihua = args.meihua
        simulate_agents = args.agents
        
        # å¤šæ¬¡é¢„æµ‹
        if args.times > 1:
            print(f"\nğŸ”„ å¼€å§‹{args.times}æ¬¡é¢„æµ‹å–å¹³å‡...")
            predictions = []
            for i in range(args.times):
                print(f"  [{i+1}/{args.times}] ", end="", flush=True)
                result = p.predict(args.template, variables=variables, enable_meihua=enable_meihua, simulate_agents=simulate_agents)
                predictions.append(result["prediction"])
                print("âœ“")
            
            # åˆå¹¶ç»“æœ
            print("\n" + "="*60)
            print(f"ğŸ“Š é¢„æµ‹ç»“æœï¼ˆ{args.times}æ¬¡ç»¼åˆï¼‰:")
            print("="*60)
            for i, pred in enumerate(predictions, 1):
                print(f"\n--- ç¬¬{i}æ¬¡é¢„æµ‹ ---\n{pred[:300]}...")
            print("="*60)
            print(f"\nğŸ“ å·²ä¿å­˜{len(predictions)}æ¡è®°å½•")
        else:
            result = p.predict(args.template, variables=variables, enable_meihua=enable_meihua, simulate_agents=simulate_agents)
            print(format_output(result, enable_meihua=enable_meihua, simulate_agents=simulate_agents))
            
    except json.JSONDecodeError as e:
        print(f"âŒ JSONè§£æé”™è¯¯: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        sys.exit(1)
    return 0


def cmd_simple_predict(args):
    """ç®€åŒ–çš„é€šç”¨é¢„æµ‹å‘½ä»¤ - æ— éœ€æ¨¡æ¿"""
    try:
        p = Predictor(glm_api_key=args.api_key)
        event = args.event
        enable_meihua = args.meihua
        simulate_agents = args.agents
        
        # æ„å»ºé€šç”¨æç¤º
        variables = {
            "äº‹ä»¶æè¿°": event,
            "æ—¶é—´": args.time or "è¿‘æœŸ",
            "åœ°ç‚¹": args.location or "ä¸é™",
            "æ¶‰åŠäººç‰©": args.persons or "å¾…å®š",
            "å½“å‰çŠ¶æ€": args.status or "è¿›è¡Œä¸­"
        }
        
        result = p.predict("universal", variables=variables, enable_meihua=enable_meihua, simulate_agents=simulate_agents)
        print(format_output(result, enable_meihua=enable_meihua, simulate_agents=simulate_agents))
            
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        sys.exit(1)
    return 0


def cmd_history(args):
    try:
        p = Predictor(glm_api_key=args.api_key)
        records = p.history(limit=args.limit)
        if records:
            print("ğŸ“œ é¢„æµ‹å†å²:")
            for r in records:
                print(f"\n[{r['timestamp']}] {r['template']}")
                print(f"  {r['prediction']}")
        else:
            print("æš‚æ— å†å²è®°å½•")
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        sys.exit(1)
    return 0


def cmd_template(args):
    try:
        p = Predictor(glm_api_key=args.api_key)
        content = p.get_template(args.name)
        print(content)
    except FileNotFoundError as e:
        print(f"âŒ {e}")
        sys.exit(1)
    return 0


def cmd_algo_predict(args):
    """ç®—æ³•é¢„æµ‹"""
    try:
        data = [float(x.strip()) for x in args.data.split(",")]
        
        if args.algorithm == "ensemble":
            predictor = EnsemblePredictor()
            result = predictor.predict(data, steps=args.steps)
            
            print("\n" + "="*60)
            print("ğŸ“Š ç®—æ³•é¢„æµ‹ç»“æœ:")
            print("="*60)
            
            print(f"\nğŸ” è¶‹åŠ¿åˆ†æ:")
            trend = result["trend"]
            print(f"  è¶‹åŠ¿æ–¹å‘: {trend['trend']}")
            print(f"  è¶‹åŠ¿å¼ºåº¦: {trend['strength']}")
            print(f"  å¹³å‡å˜åŒ–ç‡: {trend['avg_change_rate']}%")
            print(f"  æ³¢åŠ¨æ€§: {trend['volatility']}")
            print(f"  ç½®ä¿¡åº¦: {trend['confidence']}")
            
            print(f"\nğŸ”¢ å„ç®—æ³•é¢„æµ‹:")
            for name, pred in result["predictions"].items():
                if isinstance(pred, (int, float)):
                    print(f"  {name}: {pred:.2f}")
            
            print(f"\nğŸ¯ ç»¼åˆé¢„æµ‹: {result['ensemble']}")
            print("="*60)
        else:
            if args.algorithm not in ALGORITHMS:
                print(f"âŒ æœªçŸ¥ç®—æ³•: {args.algorithm}")
                sys.exit(1)
            
            algo = ALGORITHMS[args.algorithm]()
            pred = algo.predict(data, steps=args.steps)
            
            print("\n" + "="*60)
            print(f"ğŸ“Š {args.algorithm} é¢„æµ‹ç»“æœ:")
            print("="*60)
            print(f"é¢„æµ‹å€¼: {pred}")
            print("="*60)
            
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        sys.exit(1)
    return 0


def cmd_yi_predict(args):
    """æ¢…èŠ±æ˜“æ•°é¢„æµ‹"""
    try:
        kwargs = {}
        if args.method == "time":
            now = datetime.now()
            kwargs["year"] = args.year or now.year
            kwargs["month"] = args.month or now.month
            kwargs["day"] = args.day or now.day
            kwargs["hour"] = args.hour or now.hour
        elif args.method == "direction":
            if not args.direction:
                print("âŒ æ–¹ä½èµ·å¦éœ€è¦æŒ‡å®š --direction")
                sys.exit(1)
            kwargs["direction"] = args.direction
        
        result = meihua_predict(args.question, method=args.method, **kwargs)
        print(format_meihua(result))
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        sys.exit(1)
    return 0


def main():
    parser = argparse.ArgumentParser(prog="predictor", description="æœªæ¥é¢„æµ‹ç³»ç»Ÿ v0.2.0 - æ”¯æŒæ¢…èŠ±æ˜“æ•°å’Œå¤šAgentæ¨¡æ‹Ÿ")
    parser.add_argument("--version", action="version", version="%(prog)s 0.2.0")
    parser.add_argument("--api-key", dest="api_key", help="GLM API Key")
    
    subparsers = parser.add_subparsers(dest="command", help="å‘½ä»¤")
    
    parser_init = subparsers.add_parser("init", help="åˆå§‹åŒ–é…ç½®")
    parser_init.set_defaults(func=cmd_init)
    
    parser_config = subparsers.add_parser("config", help="é…ç½®ç®¡ç†")
    config_sub = parser_config.add_subparsers(dest="subcommand", help="é…ç½®å­å‘½ä»¤")
    config_show = config_sub.add_parser("show", help="æ˜¾ç¤ºé…ç½®")
    config_show.set_defaults(func=cmd_config)
    config_set = config_sub.add_parser("set", help="è®¾ç½®é…ç½®")
    config_set.add_argument("key", help="é…ç½®é¡¹")
    config_set.add_argument("value", help="é…ç½®å€¼")
    config_set.set_defaults(func=cmd_config)
    
    parser_ct = subparsers.add_parser("create-template", help="åˆ›å»ºæ¨¡æ¿")
    parser_ct.add_argument("name", help="æ¨¡æ¿åç§°")
    parser_ct.add_argument("-f", "--file", help="æ¨¡æ¿æ–‡ä»¶è·¯å¾„")
    parser_ct.set_defaults(func=cmd_create_template)
    
    parser_lt = subparsers.add_parser("list-templates", help="åˆ—å‡ºæ¨¡æ¿")
    parser_lt.set_defaults(func=cmd_list_templates)
    
    parser_tpl = subparsers.add_parser("template", help="æŸ¥çœ‹æ¨¡æ¿")
    parser_tpl.add_argument("name", help="æ¨¡æ¿åç§°")
    parser_tpl.set_defaults(func=cmd_template)
    
    # é€šç”¨é¢„æµ‹å‘½ä»¤
    parser_ask = subparsers.add_parser("ask", help="ç›´æ¥æé—®é¢„æµ‹ï¼ˆæ— éœ€æ¨¡æ¿ï¼‰")
    parser_ask.add_argument("event", help="é¢„æµ‹äº‹ä»¶æè¿°")
    parser_ask.add_argument("-t", "--time", help="æ—¶é—´")
    parser_ask.add_argument("-l", "--location", help="åœ°ç‚¹")
    parser_ask.add_argument("-p", "--persons", help="æ¶‰åŠäººç‰©")
    parser_ask.add_argument("-s", "--status", help="å½“å‰çŠ¶æ€")
    parser_ask.add_argument("-m", "--meihua", action="store_true", help="å¯ç”¨æ¢…èŠ±æ˜“æ•°åˆ†æ")
    parser_ask.add_argument("-a", "--agents", type=int, default=0, help="å¯ç”¨å¤šAgentæ¨¡æ‹Ÿæ•°é‡")
    parser_ask.set_defaults(func=cmd_simple_predict)
    
    parser_pred = subparsers.add_parser("predict", help="æ‰§è¡Œé¢„æµ‹")
    parser_pred.add_argument("template", help="æ¨¡æ¿åç§°")
    parser_pred.add_argument("-v", "--variables", help="JSONæ ¼å¼å˜é‡")
    parser_pred.add_argument("-n", "--times", type=int, default=1, help="é¢„æµ‹æ¬¡æ•°ï¼ˆå–å¹³å‡ï¼‰")
    parser_pred.add_argument("-m", "--meihua", action="store_true", help="å¯ç”¨æ¢…èŠ±æ˜“æ•°åˆ†æ")
    parser_pred.add_argument("-a", "--agents", type=int, default=0, help="å¯ç”¨å¤šAgentæ¨¡æ‹Ÿæ•°é‡")
    parser_pred.set_defaults(func=cmd_predict)
    
    parser_hist = subparsers.add_parser("history", help="æŸ¥çœ‹å†å²")
    parser_hist.add_argument("-n", "--limit", type=int, default=10, help="æ˜¾ç¤ºæ¡æ•°")
    parser_hist.set_defaults(func=cmd_history)
    
    # ç®—æ³•é¢„æµ‹
    parser_algo = subparsers.add_parser("algo", help="ç®—æ³•é¢„æµ‹")
    parser_algo.add_argument("-d", "--data", required=True, help="å†å²æ•°æ®ï¼Œé€—å·åˆ†éš”")
    parser_algo.add_argument("-s", "--steps", type=int, default=1, help="é¢„æµ‹æ­¥æ•°")
    parser_algo.add_argument("-a", "--algorithm", default="ensemble", help="ç®—æ³•: ma/ema/linear/poly/ensemble")
    parser_algo.set_defaults(func=cmd_algo_predict)
    
    # æ¢…èŠ±æ˜“æ•°
    parser_yi = subparsers.add_parser("yi", help="æ¢…èŠ±æ˜“æ•°é¢„æµ‹")
    parser_yi.add_argument("question", help="é¢„æµ‹é—®é¢˜")
    parser_yi.add_argument("-m", "--method", default="time", choices=["time", "direction", "random"], help="èµ·å¦æ–¹å¼")
    parser_yi.add_argument("-y", "--year", type=int, help="å¹´ä»½")
    parser_yi.add_argument("--month", type=int, help="æœˆä»½")
    parser_yi.add_argument("--day", type=int, help="æ—¥æœŸ")
    parser_yi.add_argument("--hour", type=int, help="å°æ—¶")
    parser_yi.add_argument("--direction", help="æ–¹ä½ï¼ˆå¦‚ï¼šä¸œã€è¥¿åŒ—ï¼‰")
    parser_yi.set_defaults(func=cmd_yi_predict)
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return 0
    
    return args.func(args)


if __name__ == "__main__":
    sys.exit(main())
