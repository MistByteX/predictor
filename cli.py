#!/usr/bin/env python3
"""
é¢„æµ‹ç³»ç»ŸCLIå·¥å…·
"""
import sys
import os
import json
import re
import argparse
from datetime import datetime
from pathlib import Path
import requests
from algorithms import ALGORITHMS, EnsemblePredictor
from meihua import predict, format_result

# é…ç½®è·¯å¾„
CONFIG_DIR = Path.home() / ".predictor"
CONFIG_FILE = CONFIG_DIR / "config.json"
TEMPLATES_DIR = Path(__file__).parent / "templates"
PREDICTIONS_DIR = Path(__file__).parent / "predictions"

__version__ = "0.1.0"


def get_config() -> dict:
    if not CONFIG_FILE.exists():
        return {}
    with open(CONFIG_FILE, encoding="utf-8") as f:
        return json.load(f)


def save_config(config: dict):
    CONFIG_DIR.mkdir(parents=True, exist_ok=True)
    with open(CONFIG_FILE, "w", encoding="utf-8") as f:
        json.dump(config, f, ensure_ascii=False, indent=2)


def fill_template(template: str, variables: dict) -> str:
    result = template
    for key, value in variables.items():
        result = result.replace(f"{{{key}}}", str(value))
    unfilled = re.findall(r'\{([^}]+)\}', result)
    if unfilled:
        raise ValueError(f"æœªå¡«å……çš„å˜é‡: {', '.join(unfilled)}")
    return result


class Predictor:
    def __init__(self, glm_api_key: str = None, glm_base_url: str = None):
        config = get_config()
        self.api_key = glm_api_key or config.get("glm_api_key")
        self.base_url = glm_base_url or config.get("glm_base_url", "https://open.bigmodel.cn/api/paas/v4")
        if not self.api_key:
            raise ValueError("è¯·è®¾ç½®GLM API Key: predictor config set api_key <your_key>")
    
    def call_glm(self, prompt: str, system_prompt: str = None) -> str:
        url = f"{self.base_url}/chat/completions"
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        messages.append({"role": "user", "content": prompt})
        
        data = {
            "model": "glm-4-flash",
            "messages": messages,
            "temperature": 0.7
        }
        
        response = requests.post(url, headers=headers, json=data, timeout=120)
        response.raise_for_status()
        result = response.json()
        return result["choices"][0]["message"]["content"]
    
    def create_template(self, name: str, content: str = None, template_file: str = None):
        TEMPLATES_DIR.mkdir(parents=True, exist_ok=True)
        if template_file:
            with open(template_file, encoding="utf-8") as f:
                content = f.read()
        if not content:
            raise ValueError("éœ€è¦æä¾›æ¨¡æ¿å†…å®¹")
        template_path = TEMPLATES_DIR / f"{name}.md"
        with open(template_path, "w", encoding="utf-8") as f:
            f.write(content)
        return str(template_path)
    
    def list_templates(self):
        TEMPLATES_DIR.mkdir(parents=True, exist_ok=True)
        return [f.stem for f in TEMPLATES_DIR.glob("*.md")]
    
    def get_template(self, name: str) -> str:
        template_path = TEMPLATES_DIR / f"{name}.md"
        if not template_path.exists():
            raise FileNotFoundError(f"æ¨¡æ¿ä¸å­˜åœ¨: {name}")
        with open(template_path, encoding="utf-8") as f:
            return f.read()
    
    def predict(self, template_name: str, variables: dict = None, system_prompt: str = None) -> dict:
        template = self.get_template(template_name)
        if variables:
            prompt = fill_template(template, variables)
        else:
            prompt = template
        
        prediction = self.call_glm(prompt, system_prompt)
        
        PREDICTIONS_DIR.mkdir(parents=True, exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        record = {
            "template": template_name,
            "variables": variables or {},
            "prompt": prompt,
            "prediction": prediction,
            "timestamp": timestamp
        }
        
        history_file = PREDICTIONS_DIR / f"{timestamp}.json"
        with open(history_file, "w", encoding="utf-8") as f:
            json.dump(record, f, ensure_ascii=False, indent=2)
        
        return {
            "prompt": prompt,
            "prediction": prediction,
            "history_file": str(history_file)
        }
    
    def history(self, limit: int = 10):
        PREDICTIONS_DIR.mkdir(parents=True, exist_ok=True)
        files = sorted(PREDICTIONS_DIR.glob("*.json"), reverse=True)[:limit]
        records = []
        for f in files:
            with open(f, encoding="utf-8") as fp:
                data = json.load(fp)
                records.append({
                    "timestamp": data["timestamp"],
                    "template": data["template"],
                    "prediction": data["prediction"][:100] + "..."
                })
        return records


def cmd_init(args):
    config = get_config()
    if not config:
        api_key = args.api_key or input("è¯·è®¾ç½®GLM API Key: ").strip()
        if api_key:
            config["glm_api_key"] = api_key
            config["glm_base_url"] = "https://open.bigmodel.cn/api/paas/v4"
            save_config(config)
            print("âœ… é…ç½®å·²ä¿å­˜")
        else:
            print("âŒ éœ€è¦API Key")
            sys.exit(1)
    else:
        print("å·²å­˜åœ¨é…ç½®:", config)
    return 0


def cmd_config(args):
    config = get_config()
    if args.subcommand == "show":
        if config:
            print(json.dumps(config, ensure_ascii=False, indent=2))
        else:
            print("æœªé…ç½®ï¼Œè¯·å…ˆè¿è¡Œ predictor init")
        return 0
    if args.subcommand == "set":
        if args.key == "api_key":
            config["glm_api_key"] = args.value
            save_config(config)
            print(f"âœ… å·²è®¾ç½® glm_api_key")
        elif args.key == "base_url":
            config["glm_base_url"] = args.value
            save_config(config)
            print(f"âœ… å·²è®¾ç½® glm_base_url")
        else:
            print(f"âŒ æœªçŸ¥é…ç½®é¡¹: {args.key}")
            sys.exit(1)
        return 0


def cmd_create_template(args):
    try:
        p = Predictor(glm_api_key=args.api_key)
        path = p.create_template(args.name, template_file=args.file)
        print(f"âœ… æ¨¡æ¿å·²åˆ›å»º: {path}")
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        sys.exit(1)
    return 0


def cmd_list_templates(args):
    try:
        p = Predictor(glm_api_key=args.api_key)
        templates = p.list_templates()
        if templates:
            print("ğŸ“‹ æ¨¡æ¿åˆ—è¡¨:")
            for t in templates:
                print(f"  - {t}")
        else:
            print("æš‚æ— æ¨¡æ¿ï¼Œè¯·å…ˆåˆ›å»º")
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        sys.exit(1)
    return 0


def cmd_predict(args):
    try:
        p = Predictor(glm_api_key=args.api_key)
        variables = None
        if args.variables:
            variables = json.loads(args.variables)
        
        # å¤šæ¬¡é¢„æµ‹
        if args.times > 1:
            print(f"\nğŸ”„ å¼€å§‹{args.times}æ¬¡é¢„æµ‹å–å¹³å‡...")
            predictions = []
            for i in range(args.times):
                print(f"  [{i+1}/{args.times}] ", end="", flush=True)
                result = p.predict(args.template, variables=variables)
                predictions.append(result["prediction"])
                print("âœ“")
            
            # åˆå¹¶ç»“æœ
            print("\n" + "="*50)
            print(f"ğŸ“Š é¢„æµ‹ç»“æœï¼ˆ{args.times}æ¬¡ç»¼åˆï¼‰:")
            print("="*50)
            for i, pred in enumerate(predictions, 1):
                print(f"\n--- ç¬¬{i}æ¬¡é¢„æµ‹ ---\n{pred[:300]}...")
            print("="*50)
            print(f"\nğŸ“ å·²ä¿å­˜{len(predictions)}æ¡è®°å½•")
        else:
            result = p.predict(args.template, variables=variables)
            print("\n" + "="*50)
            print("ğŸ“Š é¢„æµ‹ç»“æœ:")
            print("="*50)
            print(result["prediction"])
            print("="*50)
            print(f"ğŸ“ å·²ä¿å­˜è‡³: {result['history_file']}")
            
    except json.JSONDecodeError as e:
        print(f"âŒ JSONè§£æé”™è¯¯: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        sys.exit(1)
    return 0


def cmd_history(args):
    try:
        p = Predictor(glm_api_key=args.api_key)
        records = p.history(limit=args.limit)
        if records:
            print("ğŸ“œ é¢„æµ‹å†å²:")
            for r in records:
                print(f"\n[{r['timestamp']}] {r['template']}")
                print(f"  {r['prediction']}")
        else:
            print("æš‚æ— å†å²è®°å½•")
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        sys.exit(1)
    return 0


def cmd_template(args):
    try:
        p = Predictor(glm_api_key=args.api_key)
        content = p.get_template(args.name)
        print(content)
    except FileNotFoundError as e:
        print(f"âŒ {e}")
        sys.exit(1)
    return 0


def cmd_algo_predict(args):
    """ç®—æ³•é¢„æµ‹"""
    try:
        # è§£ææ•°æ®
        data = [float(x.strip()) for x in args.data.split(",")]
        
        # è·å–ç®—æ³•
        if args.algorithm == "ensemble":
            predictor = EnsemblePredictor()
            result = predictor.predict(data, steps=args.steps)
            
            print("\n" + "="*50)
            print("ğŸ“Š ç®—æ³•é¢„æµ‹ç»“æœ:")
            print("="*50)
            
            print(f"\nğŸ” è¶‹åŠ¿åˆ†æ:")
            trend = result["trend"]
            print(f"  è¶‹åŠ¿æ–¹å‘: {trend['trend']}")
            print(f"  è¶‹åŠ¿å¼ºåº¦: {trend['strength']}")
            print(f"  å¹³å‡å˜åŒ–ç‡: {trend['avg_change_rate']}%")
            print(f"  æ³¢åŠ¨æ€§: {trend['volatility']}")
            print(f"  ç½®ä¿¡åº¦: {trend['confidence']}")
            
            print(f"\nğŸ”¢ å„ç®—æ³•é¢„æµ‹:")
            for name, pred in result["predictions"].items():
                if isinstance(pred, (int, float)):
                    print(f"  {name}: {pred:.2f}")
            
            print(f"\nğŸ¯ ç»¼åˆé¢„æµ‹: {result['ensemble']}")
            print("="*50)
        else:
            if args.algorithm not in ALGORITHMS:
                print(f"âŒ æœªçŸ¥ç®—æ³•: {args.algorithm}")
                sys.exit(1)
            
            algo = ALGORITHMS[args.algorithm]()
            pred = algo.predict(data, steps=args.steps)
            
            print("\n" + "="*50)
            print(f"ğŸ“Š {args.algorithm} é¢„æµ‹ç»“æœ:")
            print("="*50)
            print(f"é¢„æµ‹å€¼: {pred}")
            print("="*50)
            
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        sys.exit(1)
    return 0


def cmd_yi_predict(args):
    """æ¢…èŠ±æ˜“æ•°é¢„æµ‹"""
    try:
        kwargs = {}
        if args.method == "time":
            now = datetime.now()
            kwargs["year"] = args.year or now.year
            kwargs["month"] = args.month or now.month
            kwargs["day"] = args.day or now.day
            kwargs["hour"] = args.hour or now.hour
        elif args.method == "direction":
            if not args.direction:
                print("âŒ æ–¹ä½èµ·å¦éœ€è¦æŒ‡å®š --direction")
                sys.exit(1)
            kwargs["direction"] = args.direction
        
        result = predict(args.question, method=args.method, **kwargs)
        print(format_result(result))
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        sys.exit(1)
    return 0


def main():
    parser = argparse.ArgumentParser(prog="predictor", description="æœªæ¥é¢„æµ‹ç³»ç»Ÿ")
    parser.add_argument("--version", action="version", version="%(prog)s 0.1.0")
    parser.add_argument("--api-key", dest="api_key", help="GLM API Key")
    
    subparsers = parser.add_subparsers(dest="command", help="å‘½ä»¤")
    
    parser_init = subparsers.add_parser("init", help="åˆå§‹åŒ–é…ç½®")
    parser_init.set_defaults(func=cmd_init)
    
    parser_config = subparsers.add_parser("config", help="é…ç½®ç®¡ç†")
    config_sub = parser_config.add_subparsers(dest="subcommand", help="é…ç½®å­å‘½ä»¤")
    config_show = config_sub.add_parser("show", help="æ˜¾ç¤ºé…ç½®")
    config_show.set_defaults(func=cmd_config)
    config_set = config_sub.add_parser("set", help="è®¾ç½®é…ç½®")
    config_set.add_argument("key", help="é…ç½®é¡¹")
    config_set.add_argument("value", help="é…ç½®å€¼")
    config_set.set_defaults(func=cmd_config)
    
    parser_ct = subparsers.add_parser("create-template", help="åˆ›å»ºæ¨¡æ¿")
    parser_ct.add_argument("name", help="æ¨¡æ¿åç§°")
    parser_ct.add_argument("-f", "--file", help="æ¨¡æ¿æ–‡ä»¶è·¯å¾„")
    parser_ct.set_defaults(func=cmd_create_template)
    
    parser_lt = subparsers.add_parser("list-templates", help="åˆ—å‡ºæ¨¡æ¿")
    parser_lt.set_defaults(func=cmd_list_templates)
    
    parser_tpl = subparsers.add_parser("template", help="æŸ¥çœ‹æ¨¡æ¿")
    parser_tpl.add_argument("name", help="æ¨¡æ¿åç§°")
    parser_tpl.set_defaults(func=cmd_template)
    
    parser_pred = subparsers.add_parser("predict", help="æ‰§è¡Œé¢„æµ‹")
    parser_pred.add_argument("template", help="æ¨¡æ¿åç§°")
    parser_pred.add_argument("-v", "--variables", help="JSONæ ¼å¼å˜é‡")
    parser_pred.add_argument("-n", "--times", type=int, default=1, help="é¢„æµ‹æ¬¡æ•°ï¼ˆå–å¹³å‡ï¼‰")
    parser_pred.set_defaults(func=cmd_predict)
    
    parser_hist = subparsers.add_parser("history", help="æŸ¥çœ‹å†å²")
    parser_hist.add_argument("-n", "--limit", type=int, default=10, help="æ˜¾ç¤ºæ¡æ•°")
    parser_hist.set_defaults(func=cmd_history)
    
    # ç®—æ³•é¢„æµ‹
    parser_algo = subparsers.add_parser("algo", help="ç®—æ³•é¢„æµ‹")
    parser_algo.add_argument("-d", "--data", required=True, help="å†å²æ•°æ®ï¼Œé€—å·åˆ†éš”")
    parser_algo.add_argument("-s", "--steps", type=int, default=1, help="é¢„æµ‹æ­¥æ•°")
    parser_algo.add_argument("-a", "--algorithm", default="ensemble", help="ç®—æ³•: ma/ema/linear/poly/ensemble")
    parser_algo.set_defaults(func=cmd_algo_predict)
    
    # æ¢…èŠ±æ˜“æ•°
    parser_yi = subparsers.add_parser("yi", help="æ¢…èŠ±æ˜“æ•°é¢„æµ‹")
    parser_yi.add_argument("question", help="é¢„æµ‹é—®é¢˜")
    parser_yi.add_argument("-m", "--method", default="time", choices=["time", "direction", "random"], help="èµ·å¦æ–¹å¼")
    parser_yi.add_argument("-y", "--year", type=int, help="å¹´ä»½")
    parser_yi.add_argument("--month", type=int, help="æœˆä»½")
    parser_yi.add_argument("--day", type=int, help="æ—¥æœŸ")
    parser_yi.add_argument("--hour", type=int, help="å°æ—¶")
    parser_yi.add_argument("--direction", help="æ–¹ä½ï¼ˆå¦‚ï¼šä¸œã€è¥¿åŒ—ï¼‰")
    parser_yi.set_defaults(func=cmd_yi_predict)
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return 0
    
    return args.func(args)


if __name__ == "__main__":
    sys.exit(main())
